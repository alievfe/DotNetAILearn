## notebook

### 使用笔记本

- vscode安装 polyglot notebook

- 打开[semantic-kernel/dotnet/notebooks at main · microsoft/semantic-kernel](https://github.com/microsoft/semantic-kernel/tree/main/dotnet/notebooks)





- 语义插件（Semantic Plugin）是语义函数的集合，其中每个函数都用自然语言定义，自然语言可以通过文本文件提供。



### 术语表

- **语义内核**（Semantic Kernel, SK）- 协调者，它通过SK可用的插件（PLUGINS）来满足用户的请求（ASK）。
- **请求**（Ask）- 用户向语义内核提出的要求，以协助达成用户的目标。
  - “向SK提出请求（ASKs）”
- **插件**（Plugins）- 一系列针对特定领域的、经过精细调整的函数集合，作为整体提供给SK使用。
  - “有一个用于更好地使用Office的插件”
- **函数**（Function）- 由语义AI和/或原生代码组成的计算单元，存在于某个插件（PLUGIN）中。
  - “Office插件包含许多函数（FUNCTIONS）” 
- **原生函数**（Native Function）- 使用传统编程语言（如C#、Python、TypeScript）表达，并能与SK轻松集成。
- **语义函数**（Semantic Function）- 在文本文件 "skprompt.txt" 中以自然语言表述，采用SK提示模板语言。每个语义函数都由一个独特的提示模板文件定义，这些文件是利用现代提示工程技术开发的。
- **记忆**（Memory）- 一个基于事实、事件、文档的语义知识集合，通过嵌入式索引进行组织。 

> - 内核设计鼓励函数组合，允许用户将多个函数（原生和语义）合并成单一的流水线。

<img src="./01img/221690406-caaff98e-87b5-40b7-9c58-cfa9623789b5.png" alt="image" style="zoom:67%;" />

<img src="./01img/221690156-3f90a8c9-ef90-46f7-a097-beb483656e97.png" alt="image" style="zoom: 67%;" />

config.json

```json
{
  "schema": 1,
  "description": "Generate a funny joke",
  "execution_settings": [
    {
      "max_tokens": 1000,
      "temperature": 0.9,
      "top_p": 0.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0
    }
  ]
}
```



### function calling

- 配置迁移：[Migrating to the new Function Calling capabilities | Microsoft Learn](https://learn.microsoft.com/en-gb/semantic-kernel/support/migration/function-calling-migration-guide?pivots=programming-language-csharp)

```cs
// Before
var executionSettings = new OpenAIPromptExecutionSettings { ToolCallBehavior = ToolCallBehavior.AutoInvokeKernelFunctions };

// After
var executionSettings = new OpenAIPromptExecutionSettings { FunctionChoiceBehavior = FunctionChoiceBehavior.Auto() };
```

- 调用时候还可以通过使用 `IChatCompletionService` 运行它，以访问 `ChatHistory` 对象，以查看哪些函数作为函数调用过程的一部分被调用。注意，需要将 Kernel 作为参数传递给 `GetChatMessageContentAsync` 方法，因为 Kernel 包含有关可用插件的信息。

```cs
var chatCompletionService = kernel.GetRequiredService<IChatCompletionService>();

var chatHistory = new ChatHistory();

chatHistory.AddUserMessage(ask);

var chatCompletionResult = await chatCompletionService.GetChatMessageContentAsync(chatHistory, openAIPromptExecutionSettings, kernel);

Console.WriteLine($"Result: {chatCompletionResult}\n");
Console.WriteLine($"Chat history: {JsonSerializer.Serialize(chatHistory)}\n");
```



### 函数嵌套





### 向量存储

> - https://github.com/microsoft/semantic-kernel/blob/main/dotnet/notebooks/06-vector-stores-and-embeddings.ipynb

- 之前主要将内核视为无状态编排引擎，即文本发送到模型 API 并接收文本。
- 但是如果仅依赖内核参数，最终 prompt 会变得巨大，以至于会遇到模型的 token 限制。所以需要的是一种持久化状态并构建短期和长期内存的方法，以增强更智能的应用程序。

**安装**

- Package `Microsoft.Extensions.VectorData.Abstractions` ，其中包含使用矢量存储所需的所有抽象。

- 然后还需要使用具体数据库连接器的实现。此处使用内存中连接器进行演示 - `Microsoft.SemanticKernel.Connectors.InMemory` 。
  - 支持的连接器：Azure AI Search、Azure CosmosDB、Qdrant、Redis 等。[更多连接器](https://learn.microsoft.com/en-us/semantic-kernel/concepts/vector-store-connectors/out-of-the-box-connectors/)

**定义模型**

- 在抽象中，有三种主要的数据模型属性类型：

  - Key 键

  - Data 数据

  - Vector 向量

- 一般数据模型包含一个 key 属性、多个 data 和 vector 属性
  - 某些连接器可能有限制，例如当仅支持一个 vector property 时。
  - 此外，每个连接器都支持一组不同的属性类型。[连接器支持的属性类型](https://learn.microsoft.com/en-us/semantic-kernel/concepts/vector-store-connectors/out-of-the-box-connectors/)。

- 有两种方法可以定义数据模型
  - 使用特性（声明式方式）
  - 记录定义（命令式方式）
- 以下使用特性定义

```cs
public sealed class Glossary
{
    [VectorStoreRecordKey]
    public ulong Key { get; set; }

    [VectorStoreRecordData]
    public string Term { get; set; }

    [VectorStoreRecordData]
    public string Definition { get; set; }

    [VectorStoreRecordVector(Dimensions: 2560)]
    public ReadOnlyMemory<float> DefinitionEmbedding { get; set; }
}
```

- 在某些情况下无法使用特性添加到现有类上。此时可以定义一个单独的记录定义，其中包含有关属性的所有信息。注意这种情况下，定义的数据模型类仍然是必需的：

```cs
public sealed class GlossaryWithoutAttributes
{
    public ulong Key { get; set; }

    public string Term { get; set; }

    public string Definition { get; set; }

    public ReadOnlyMemory<float> DefinitionEmbedding { get; set; }
}

var recordDefinition = new VectorStoreRecordDefinition()
{
    Properties = new List<VectorStoreRecordProperty>()
    {
        new VectorStoreRecordKeyProperty("Key", typeof(ulong)),
        new VectorStoreRecordDataProperty("Term", typeof(string)),
        new VectorStoreRecordDataProperty("Definition", typeof(string)),
        new VectorStoreRecordVectorProperty("DefinitionEmbedding", typeof(ReadOnlyMemory<float>)) { Dimensions = 1536 }
    }
};
```

**向量存储库和集合创建**

- 定义数据模型后就可以开始在选择的数据库中使用它，涉及到的抽象接口

  - `IVectorStoreRecordCollection<TKey, TRecord>`：表示一个集合。此集合可能存在也可能不存在，并且提供了检查集合是否存在、创建、更新插入、获取和删除记录的方法。该接口继承自 `IVectorizedSearch<TRecord>`，提供向量搜索功能。

  - `IVectorStore`：包含跨向量存储中所有集合的操作，例如 `ListCollectionNames`。它还提供获取 `IVectorStoreRecordCollection<TKey, TRecord>` 实例的功能。

  - 每个连接器都有扩展方法支持依赖注入：`services.AddInMemoryVectorStore()` 或 `services.AddInMemoryVectorStoreRecordCollection("collection-name")` 。

- 以下直接初始化实例使用，集合类似于关系数据库中的表。

```cs
// 创建向量存储库
var vectorStore = new InMemoryVectorStore();
// 通过向量存储库获取集合
var colleciton = vectorStore.GetCollection<ulong, Glossary>("skglossary");
// 通过直接初始化获取集合
var colleciton2 = new InMemoryVectorStoreRecordCollection<ulong, Glossary>("skglossary");
// 确保集合存在于数据库中
await colleciton.CreateCollectionIfNotExistsAsync();
```

**文本向量化存储**

- 首先需要对源数据集合遍历处理生成向量，使用ITextEmbeddingGenerationService的GenerateEmbeddingAsync方法。此时会请求embedding接口。
- 向量化完成后，使用collection的UpsertAsync或UpsertBatchAsync 方法存入向量数据库中。
  - 此操作幂等：如果不存在具有特定键的记录，则会插入该记录。如果它已存在，则将对其进行更新

```cs
// 准备数据
List<Glossary> glossaryEntries =
[
    new Glossary()
    {
        Key = 1,
        Term = "API",
        Definition =
            "Application Programming Interface. A set of rules and specifications that allow software components to communicate and exchange data.",
    },
    new Glossary()
    {
        Key = 2,
        Term = "Connectors",
        Definition =
            "Connectors allow you to integrate with various services provide AI capabilities, including LLM, AudioToText, TextToAudio, Embedding generation, etc.",
    },
    new Glossary()
    {
        Key = 3,
        Term = "RAG",
        Definition =
            "Retrieval Augmented Generation - a term that refers to the process of retrieving additional data to provide as context to an LLM to use when generating a response (completion) to a user's question (prompt).",
    },
];


// 如果想对数据库中的记录执行向量搜索，仅初始化 key 和 data 属性是不够的，还需要生成和初始化向量属性。为此，可以使用 ITextEmbeddingGenerationService。
var textEmbeddingGenerationService =
    kernel.GetRequiredService<ITextEmbeddingGenerationService>();
var tasks = glossaryEntries.Select(e =>
    Task.Run(async () =>
    {
        e.DefinitionEmbedding = await textEmbeddingGenerationService.GenerateEmbeddingAsync(
            e.Definition
        );
    })
);
await Task.WhenAll(tasks);


// 插入到数据库中。可以使用collection的UpsertAsync或UpsertBatchAsync 方法。此操作幂等 - 如果不存在具有特定键的记录，则会插入该记录。如果它已存在，则将对其进行更新
await foreach (var key in colleciton.UpsertBatchAsync(glossaryEntries))
{
    Console.WriteLine(key);
}
```

**查询向量数据**

- 使用 collection.GetAsync 或 GetBatchAsync按键获取记录。支持GetRecordOptions作为参数指定是否要在响应中包含向量属性。
  - 因为 vector 维度值可能很高，不推荐从数据库中获取。所以 GetRecordOptions.IncludeVectors = false 是默认值。（这里为了测试所以需要看到向量）

```cs
var options = new GetRecordOptions() { IncludeVectors = true };
await foreach (var record in colleciton.GetBatchAsync(keys: [1, 2, 3], options))
{
    System.Console.WriteLine(record.Definition);
    await record.SerializeObjectToFile();
}
```

**搜索向量**

- 查询字符串再调用embedding服务生成搜索向量。
- 然后使用IVectorStoreRecordCollection的VectorizedSearchAsync方法搜索，其接受 VectorSearchOptions 作为参数允许配置向量搜索操作
  - 指定要返回的最大记录数、返回结果之前要跳过的结果数、在执行向量搜索之前要使用的搜索过滤器等。

```cs
// 搜索，，
var searchString = "I want to learn more about Connectors";
var searchVector = await textEmbeddingGenerationService.GenerateEmbeddingAsync(
    searchString
);

var searchResult = await colleciton.VectorizedSearchAsync(searchVector);
await foreach (var result in searchResult.Results)
{
    Console.WriteLine($"Search score: {result.Score}");
    Console.WriteLine($"Key: {result.Record.Key}");
    Console.WriteLine($"Term: {result.Record.Term}");
    Console.WriteLine($"Definition: {result.Record.Definition}");
    Console.WriteLine("=========");
}
```

- 结果

```
Search score: 0.785374104976654
Key: 2
Term: Connectors
Definition: Connectors allow you to integrate with various services provide AI capabilities, including LLM, AudioToText, TextToAudio, Embedding generation, etc.
=========
Search score: 0.7311795353889465
Key: 1
Term: API
Definition: Application Programming Interface. A set of rules and specifications that allow software components to communicate and exchange data.
=========
Search score: 0.6290566325187683
Key: 3
Term: RAG
Definition: Retrieval Augmented Generation - a term that refers to the process of retrieving additional data to provide as context to an LLM to use when generating a response (completion) to a user's question (prompt).
=========
```



### 图像生成

- 以下使用 OpenAI DALL-E 3 生成图像，并结合其他 LLM 功能（如文本和嵌入生成）。

- 首先使用 Chat Completion 生成随机图像描述然后 DALL-E 3 从该描述创建图像，并内联显示图像。
- 最后要求用户描述图像。使用 Cosine Similarity 将用户描述的嵌入与原始描述进行比较，并返回从 0 到 1 的分数，其中 1 表示完全匹配。
- 安装
  - System.Numerics.Tensors
  - SkiaSharp

- 准备服务

```cs
builder.AddOpenAITextEmbeddingGeneration("text-embedding-ada-002", apiKey, orgId); // 用于将猜测与真实图像描述进行比较
builder.AddOpenAIChatCompletion(model, apiKey, orgId);
builder.AddOpenAITextToImage(apiKey, orgId); // 默认就是OpenAI Dall-E 3
```

**生成图片**

```cs
var prompt = @"
思考一个与数字{{$input}}有关的人工制品。
用一句详细的话来描述这个图像。描述中不能包含数字。";

var executionSettings = new OpenAIPromptExecutionSettings 
{
    MaxTokens = 256,
    Temperature = 1
};

// 创建一个语义函数，用于生成随机图像描述。
var genImgDescription = kernel.CreateFunctionFromPrompt(prompt, executionSettings);

var random = new Random().Next(0, 200);
var imageDescriptionResult = await kernel.InvokeAsync(genImgDescription, new() { ["input"] = random });
var imageDescription = imageDescriptionResult.ToString();

// 使用DALL-E 3来生成一张图片。在这个例子中OpenAI返回的是一个URL（虽然可以要求它返回base64编码的图片）
var imageUrl = await dallE.GenerateImageAsync(imageDescription.Trim(), 1024, 1024);

await SkiaUtils.ShowImage(imageUrl, 1024, 1024);
```

- 尝试猜测图像是关于什么的。

```cs
// 提示用户猜测图像的内容
var guess = await InteractiveKernel.GetInputAsync("请用你自己的话描述这张图片");

// 比较用户的猜测与实际描述并计算得分
var origEmbedding = await textEmbedding.GenerateEmbeddingsAsync(new List<string> { imageDescription });
var guessEmbedding = await textEmbedding.GenerateEmbeddingsAsync(new List<string> { guess });
var similarity = TensorPrimitives.CosineSimilarity(origEmbedding.First().Span, guessEmbedding.First().Span);

Console.WriteLine($"你的描述:\n{Utils.WordWrap(guess, 90)}\n");
Console.WriteLine($"实际描述:\n{Utils.WordWrap(imageDescription.Trim(), 90)}\n");
Console.WriteLine($"得分: {similarity:0.00}\n\n");

// 取消注释以下行以查看OpenAI提供的URL
// Console.WriteLine(imageUrl);
```



### 带有 BingSearch 的 RAG

- 如何将必应搜索与语义内核集成，以便从 Internet 获取最新信息。

- 使用 Bing 搜索需要 API 密钥，通过在 Azure 中创建[必应搜索资源](https://learn.microsoft.com/en-us/bing/search-apis/bing-web-search/create-bing-search-service-resource)来获取 API 密钥。

**安装**

- Microsoft.SemanticKernel.Plugins.Web
- Microsoft.SemanticKernel.Plugins.Core
- Microsoft.SemanticKernel.PromptTemplates.Handlebars

**BingSearch密钥**

- 使用 [`.NET Interactive`](https://github.com/dotnet/interactive/blob/main/docs/kernels-overview.md) 中引入的 `InteractiveKernel` 方法在 BING_KEY 中输入 Bing 搜索密钥

```cs
using InteractiveKernel = Microsoft.DotNet.Interactive.Kernel;

string BING_KEY = (await InteractiveKernel.GetPasswordAsync("Please enter your Bing Search Key")).GetClearTextPassword();
```



**基本搜索插件**

- 以下演示如何从 `BingTextSearch` 的实例创建名为 SearchPlugin 的插件。
- 使用 `CreateWithSearch` 会创建一个新插件，其中包含一个调用底层文本搜索实现的 Search 函数。SearchPlugin 被添加到 Kernel 中，使它可以在提示渲染期间被调用。
- 提示模板包括一个调用，该 `{{SearchPlugin.Search $query}}` 调用将调用 SearchPlugin 来检索与当前查询相关的结果。然后结果将插入到呈现的提示中，然后再将其发送到 AI 模型。

```cs
// 创建一个使用OpenAI聊天补全的内核
var builder = Kernel.CreateBuilder();

// 配置内核使用的AI后端
var (useAzureOpenAI, model, azureEndpoint, apiKey, orgId) = Settings.LoadFromFile();
if (useAzureOpenAI)
    builder.AddAzureOpenAIChatCompletion(model, azureEndpoint, apiKey);
else
    builder.AddOpenAIChatCompletion(model, apiKey, orgId);
var kernel = builder.Build();

// 使用Bing搜索创建一个文本搜索工具
#pragma warning disable SKEXP0050
var textSearch = new BingTextSearch(apiKey: BING_KEY);

// 构建一个带有必应搜索功能的文本搜索插件，并添加到内核中
var searchPlugin = textSearch.CreateWithSearch("SearchPlugin");
kernel.Plugins.Add(searchPlugin);

// 调用提示并使用文本搜索插件来提供基础信息
var query = "What is the Semantic Kernel?";
var prompt = "{{SearchPlugin.Search $query}}. {{$query}}";
KernelArguments arguments = new() { { "query", query } };
Console.WriteLine(await kernel.InvokePromptAsync(prompt, arguments));
```



**带引文的搜索插件**

- 下面的示例重复了上面描述的模式，但有些显著的变化。

  - `CreateWithGetTextSearchResults` 用于创建 `SearchPlugin`，该插件从底层文本搜索实现中调用 `GetTextSearchResults` 方法。

  - 提示模板使用 Handlebars 语法。这允许模板迭代搜索结果并呈现每个结果的名称、值和链接。

  - 该提示包含引用的说明，因此 AI 模型将执行向响应添加引用的工作。

```cs
// 创建带有 OpenAI 聊天完成的内核
var builder = Kernel.CreateBuilder();

// 配置内核使用的 AI 后端
var (useAzureOpenAI, model, azureEndpoint, apiKey, orgId) = Settings.LoadFromFile();
if (useAzureOpenAI)
    builder.AddAzureOpenAIChatCompletion(model, azureEndpoint, apiKey);
else
    builder.AddOpenAIChatCompletion(model, apiKey, orgId);
var kernel = builder.Build();

// 使用必应搜索创建文本搜索
#pragma warning disable SKEXP0050
var textSearch = new BingTextSearch(apiKey: BING_KEY);

// 构建一个带有必应搜索的文本搜索插件并添加到内核中
var searchPlugin = textSearch.CreateWithGetTextSearchResults("SearchPlugin");
kernel.Plugins.Add(searchPlugin);

// 调用提示，并使用文本搜索插件提供基础信息
var query = "什么是语义内核？";
string promptTemplate = """
{{#with (SearchPlugin-GetTextSearchResults query)}}  
    {{#each this}}  
    名称: {{Name}}
    内容: {{Value}}
    链接: {{Link}}
    -----------------
    {{/each}}  
{{/with}}  

{{query}}

在响应中引用相关资料的地方包含引文。
""";
KernelArguments arguments = new() { { "query", query } };
HandlebarsPromptTemplateFactory promptTemplateFactory = new();
Console.WriteLine(await kernel.InvokePromptAsync(
    promptTemplate,
    arguments,
    templateFormat: HandlebarsPromptTemplateFactory.HandlebarsTemplateFormat,
    promptTemplateFactory: promptTemplateFactory
));
```



**带有过滤器的搜索插件**

- 目前的示例使用排名靠前的 Web 搜索结果来提供接地数据。为了提高可靠性，可以将 Web 搜索限制仅返回指定站点的结果。
- 基于上一个示例添加搜索结果的筛选。带有相等子句的 `TextSearchFilter` 用于指定搜索结果中仅包含来自 Microsoft 开发人员博客站点 （ `site == 'devblogs.microsoft.com'` ）的结果。
- 该示例用于创建 `KernelPluginFactory.CreateFromFunctions` `SearchPlugin`。为插件提供了自定义描述。 `ITextSearch.CreateGetTextSearchResults` 扩展方法用于创建调用文本搜索服务的 `KernelFunction`。

```cs
// 创建带有 OpenAI 聊天完成的内核
var builder = Kernel.CreateBuilder();

// 配置内核使用的 AI 后端
var (useAzureOpenAI, model, azureEndpoint, apiKey, orgId) = Settings.LoadFromFile();
if (useAzureOpenAI)
    builder.AddAzureOpenAIChatCompletion(model, azureEndpoint, apiKey);
else
    builder.AddOpenAIChatCompletion(model, apiKey, orgId);
var kernel = builder.Build();

// 使用必应搜索创建文本搜索
#pragma warning disable SKEXP0050
var textSearch = new BingTextSearch(apiKey: BING_KEY);

// 创建一个筛选器，仅搜索 Microsoft Developer Blogs 网站
#pragma warning disable SKEXP0001
var filter = new TextSearchFilter().Equality("site", "devblogs.microsoft.com");
var searchOptions = new TextSearchOptions() { Filter = filter };

// 构建一个带有必应搜索的文本搜索插件，并添加到内核中，专门用于搜索 Microsoft Developer Blogs 网站
var searchPlugin = KernelPluginFactory.CreateFromFunctions(
    "SearchPlugin", "仅搜索 Microsoft Developer Blogs 网站",
    [textSearch.CreateGetTextSearchResults(searchOptions: searchOptions)]);
kernel.Plugins.Add(searchPlugin);

// 调用提示，并使用文本搜索插件提供基础信息
var query = "什么是语义内核？";
string promptTemplate = """
{{#with (SearchPlugin-GetTextSearchResults query)}}  
    {{#each this}}  
    名称: {{Name}}
    内容: {{Value}}
    链接: {{Link}}
    -----------------
    {{/each}}  
{{/with}}  

{{query}}

在响应中引用相关资料的地方包含引文。
""";
KernelArguments arguments = new() { { "query", query } };
HandlebarsPromptTemplateFactory promptTemplateFactory = new();
Console.WriteLine(await kernel.InvokePromptAsync(
    promptTemplate,
    arguments,
    templateFormat: HandlebarsPromptTemplateFactory.HandlebarsTemplateFormat,
    promptTemplateFactory: promptTemplateFactory
));
```



## xzy

### planner分步规划器

- 分步和 Handlebars 规划器仍可在语义内核中使用。 但是，建议对大多数任务使用函数调用，因为它更强大且更易于使用。 后续版本的SK中将弃用分步和 Handlebars 规划器。如果要生成新的 AI 代理，建议 *不要* 使用 Stepwise 或 Handlebars planners。 请改用函数调用，因为它更强大且更易于使用。
  - [.NET 从 Stepwise Planner 迁移到自动函数调用 | Microsoft Learn](https://learn.microsoft.com/zh-cn/semantic-kernel/support/migration/stepwise-planner-migration-guide?pivots=programming-language-csharp)

```cs
/// <summary>
/// 计划测试
/// </summary>
/// <param name="msg">
/// 案例输入：1.小明有7个冰淇淋，我有2个冰淇淋，他比我多几个冰淇淋？
/// 2.小明有7个冰淇淋，我有2个冰淇淋，一共有几个冰淇淋？
/// </param>
/// <returns></returns> <summary>
public async Task PlanTest(string msg)
{
    var planner = new HandlebarsPlanner(
        new HandlebarsPlannerOptions()
        {
            // 如果您想使用循环进行测试，而不管模型选择如何，请更改此设置。
            AllowLoops = true,
        }
    );
    kernel.ImportPluginFromDefaultPathPromptDirectory("Calculate");
    var plan = await planner.CreatePlanAsync(kernel, msg);
    Console.WriteLine("Plan:\n");
    Console.WriteLine(JsonSerializer.Serialize(plan));

    var res = await plan.InvokeAsync(kernel);
    System.Console.WriteLine(res);
}
```



### pipeline

```cs
/// <summary>
/// 管道 现在已经废弃了，使用的是dump之前的SK库代码
/// https://learn.microsoft.com/en-us/semantic-kernel/ai-orchestration/plugins/out-of-the-box-plugins?tabs=Csharp#whats-the-ms-graph-connector-kit
/// </summary>
/// <returns></returns>
public async Task PipelineTest()
{
    var textPlugin = kernel.ImportPluginFromType<TextPlugin>();
    KernelFunction pipeline = KernelFunctionCombinators.Pipe(
        [
            textPlugin["TrimStart"], //清除左边空格
            textPlugin["TrimEnd"], //清除右边空格
            textPlugin["Uppercase"], //转大写
        ],
        "pipeline"
    );
    var res = await pipeline.InvokeAsync(
        kernel,
        new KernelArguments() { ["input"] = "     i n f i n i t e     s p a c e     " }
    );
    System.Console.WriteLine(res);
}
```



- 相关代码

```cs
using System;
using Microsoft.SemanticKernel;

namespace SKUtils.SKExtensions;

public static class KernelFunctionCombinators
{
    /// <summary>
    /// 调用一个函数管道，按顺序运行每个函数，并将一个函数的输出作为下一个函数的第一个参数传递。
    /// </summary>
    /// <param name="functions">要调用的函数管道。</param>
    /// <param name="kernel">用于操作的内核。</param>
    /// <param name="arguments">参数。</param>
    /// <param name="cancellationToken">用于监视取消请求的取消令牌。</param>
    /// <returns>KernelFunction 运行结果</returns>
    public static Task<FunctionResult> InvokePipelineAsync(
        IEnumerable<KernelFunction> functions,
        Kernel kernel,
        KernelArguments arguments,
        CancellationToken cancellationToken
    ) => Pipe(functions).InvokeAsync(kernel, arguments, cancellationToken);

    /// <summary>
    /// 调用一个函数管道，按顺序运行每个函数，并将一个函数的输出作为命名参数传递给下一个函数。
    /// </summary>
    /// <param name="functions">要调用的函数序列，以及分配给函数调用结果的参数名称。</param>
    /// <param name="kernel">用于操作的内核。</param>
    /// <param name="arguments">参数。</param>
    /// <param name="cancellationToken">用于监视取消请求的取消令牌。</param>
    /// <returns>KernelFunction 运行结果</returns>
    public static Task<FunctionResult> InvokePipelineAsync(
        IEnumerable<(KernelFunction Function, string OutputVariable)> functions,
        Kernel kernel,
        KernelArguments arguments,
        CancellationToken cancellationToken
    ) => Pipe(functions).InvokeAsync(kernel, arguments, cancellationToken);

    /// <summary>
    /// 创建一个函数，其调用将依次调用每个提供的函数。
    /// </summary>
    /// <param name="functions">要调用的函数管道。</param>
    /// <param name="functionName">组合操作的名称。</param>
    /// <param name="description">组合操作的描述。</param>
    /// <returns>最后一个函数的结果。</returns>
    /// <remarks>
    /// 一个函数的结果将作为下一个函数的第一个参数传递。
    /// </remarks>
    public static KernelFunction Pipe(
        IEnumerable<KernelFunction> functions,
        string? functionName = null,
        string? description = null
    )
    {
        ArgumentNullException.ThrowIfNull(functions);
        KernelFunction[] funcs = functions.ToArray();
        Array.ForEach(funcs, f => ArgumentNullException.ThrowIfNull(f));

        // 创建一个包含函数和输出变量名的元组数组。如果不是最后一个函数，获取下一个函数的第一个参数名
        var funcsAndVars = new (KernelFunction Function, string OutputVariable)[funcs.Length];
        for (int i = 0; i < funcs.Length; i++)
        {
            string p = "";
            if (i < funcs.Length - 1)
            {
                var parameters = funcs[i + 1].Metadata.Parameters;
                if (parameters.Count > 0)
                {
                    p = parameters[0].Name;
                }
            }
            // 将当前函数和下一个函数的第一个参数名存入元组数组
            funcsAndVars[i] = (funcs[i], p);
        }
        return Pipe(funcsAndVars, functionName, description);
    }

    /// <summary>
    /// 创建一个函数，其调用将依次调用每个提供的函数。
    /// </summary>
    /// <param name="functions">要调用的函数管道，以及分配给函数调用结果的参数名称。</param>
    /// <param name="functionName">组合操作的名称。</param>
    /// <param name="description">组合操作的描述。</param>
    /// <returns>最后一个函数的结果。</returns>
    /// <remarks>
    /// 一个函数的结果将作为下一个函数的第一个参数传递。
    /// </remarks>
    public static KernelFunction Pipe(
        IEnumerable<(KernelFunction Function, string OutputVariable)> functions,
        string? functionName = null,
        string? description = null
    )
    {
        ArgumentNullException.ThrowIfNull(functions);

        (KernelFunction Function, string OutputVariable)[] arr = functions.ToArray();
        Array.ForEach(
            arr,
            f =>
            {
                ArgumentNullException.ThrowIfNull(f.Function);
                ArgumentNullException.ThrowIfNull(f.OutputVariable);
            }
        );
        // 使用 KernelFunctionFactory 创建一个新的 KernelFunction
        return KernelFunctionFactory.CreateFromMethod(
            async (Kernel kernel, KernelArguments arguments) =>
            {
                FunctionResult? result = null;
                // 遍历函数数组，依次调用每个函数。如果不是最后一个函数，将当前函数的结果存入参数集合中，作为下一个函数的输入
                for (int i = 0; i < arr.Length; i++)
                {
                    result = await arr[i]
                        .Function.InvokeAsync(kernel, arguments)
                        .ConfigureAwait(false);
                    if (i < arr.Length - 1)
                    {
                        arguments[arr[i].OutputVariable] = result.GetValue<object>();
                    }
                }

                return result;
            },
            functionName,
            description
        );
    }
}
```



### kernel memory（旧）

**Kernel Memory是如何工作的？**

- 嵌入是一种将单词或其他数据表示为高维空间中的向量的方式。 
- 高维空间意味着空间具有许多维度，相似的单词或数据将具有相似的向量，而不同的单词或数据将具有不同的向量。 这有助于衡量它们的关联程度或无关程度，并且执行一些操作，比如加法、减法、乘法等。嵌入对AI模型很有用，因为它们可以以计算机可以理解和处理的方式捕捉单词或数据的含义和上下文。 
- 当进行查询时，查询会被转换为其嵌入表示，然后通过所有现有的嵌入向量进行搜索，以找到最相似的内容。 
  - 这类似于在Bing上进行搜索查询时，它会给你多个与你查询相关的结果。
- Kernel Memory不太可能给你一个完全匹配的结果，但它总是会给你一组匹配项，以与其他文本多相似程度排名。



**为什么在LLM AI中Embedding是重要的？**

- 由于提示是输入到AI模型中以生成所需输出或响应的文本，需要考虑输入文本的长度，基于选择使用的模型的令牌限制。 
  - 例如，GPT-4可以处理每个输入高达8,192个令牌，而GPT-3只能处理多达4,096个令牌。这意味着长于模型令牌限制的文本将无法适应，可能会被截断或忽略。 
  - 如果能够使用整整一本10,000页的操作手册作为提示的文本，那将会很好，但由于令牌限制的约束，这是不可能的。因此，嵌入对于将这个大文本分解为较小的部分是非常有用的。 
  - 可以通过将每一页进行总结成一个较短的段落，然后为每个摘要生成一个嵌入向量来实现这一点。 
- 嵌入向量就像是文本的压缩表示，能保留其含义和上下文。然后可以比较摘要的嵌入向量和提示的嵌入向量，选择最相似的摘要。然后，可以将这些摘要添加到的输入文本中，作为提示的上下文。 通过这种方式，可以利用Embedding来帮助选择和适应作为模型标记限制内的大文本作为上下文。



**什么是Embeddings?**

- Embeddings是表示模型处理的标记的含义和上下文的数字向量或数组。
- 用于对输入和输出文本进行编码和解码，大小和维度可以不同。Embeddings可以帮助模型理解标记之间的关系，并生成相关和连贯的文本。



**什么是vector-db?**

- `vector-db`是一种数据库类型，它将数据存储为高维向量，这些向量是特征或属性的数学表示。
- 每个向量都具有一定数量的维度，取决于数据的复杂性和细粒度，维度可以在几十到数千之间。这些向量通常是通过对原始数据应用某种转换或嵌入函数生成的，比如文本、图像、音频、视频等。嵌入函数可以基于各种方法，如机器学习模型、词嵌入、特征提取算法。
-  `vector-db`的主要优势在于它能够快速准确地进行相似度搜索，并根据矢量距离或相似度检索数据。这意味着，你可以使用`vector-db`来查找语义或上下文含义最相似或相关的数据，而不是使用基于精确匹配或预定义条件的传统查询数据库方法。

**支持的连接器**

| 服务                                          |                              C#                              |                            Python                            |
| :-------------------------------------------- | :----------------------------------------------------------: | :----------------------------------------------------------: |
| Azure Cosmos DB 中的 MongoDB vCore 向量数据库 |                                                              | [Python](https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/memory/azure_cosmosdb) |
| Azure AI 搜索                                 | [C#](https://github.com/microsoft/semantic-kernel/tree/main/dotnet/src/Connectors/Connectors.Memory.AzureAISearch) | [Python](https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/memory/azure_cognitive_search) |
| Azure PostgreSQL服务器                        | [C#](https://github.com/microsoft/semantic-kernel/tree/main/dotnet/src/Connectors/Connectors.Memory.Postgres) |                                                              |
| Azure SQL数据库                               | [C#](https://github.com/kbeaugrand/SemanticKernel.Connectors.Memory.SqlServer) |                                                              |
| Chroma                                        | [C#](https://github.com/microsoft/semantic-kernel/tree/main/dotnet/src/Connectors/Connectors.Memory.Chroma) | [Python](https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/memory/chroma) |
| DuckDB                                        | [C#](https://github.com/microsoft/semantic-kernel/tree/main/dotnet/src/Connectors/Connectors.Memory.DuckDB) |                                                              |
| Milvus                                        | [C#](https://github.com/microsoft/semantic-kernel/tree/main/dotnet/src/Connectors/Connectors.Memory.Milvus) | [Python](https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/memory/milvus) |
| MongoDB Atlas Vector Search                   | [C#](https://github.com/microsoft/semantic-kernel/tree/main/dotnet/src/Connectors/Connectors.Memory.MongoDB) | [Python](https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/memory/mongodb_atlas) |
| Pinecone                                      | [C#](https://github.com/microsoft/semantic-kernel/tree/main/dotnet/src/Connectors/Connectors.Memory.Pinecone) | [Python](https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/memory/pinecone) |
| Postgres                                      | [C#](https://github.com/microsoft/semantic-kernel/tree/main/dotnet/src/Connectors/Connectors.Memory.Postgres) | [Python](https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/memory/postgres) |
| Qdrant                                        | [C#](https://github.com/microsoft/semantic-kernel/tree/main/dotnet/src/Connectors/Connectors.Memory.Qdrant) |                                                              |
| Redis                                         | [C#](https://github.com/microsoft/semantic-kernel/tree/main/dotnet/src/Connectors/Connectors.Memory.Redis) |                                                              |
| Sqlite                                        | [C#](https://github.com/microsoft/semantic-kernel/tree/main/dotnet/src/Connectors/Connectors.Memory.Sqlite) |                                                              |
| Weaviate                                      | [C#](https://github.com/microsoft/semantic-kernel/tree/main/dotnet/src/Connectors/Connectors.Memory.Weaviate) | [Python](https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/memory/weaviate) |



**案例**

- 基本查询向量

```cs
/// <summary>
/// 查询向量
/// </summary>
/// <param name="text"></param>
/// <returns></returns>
[HttpPost]
public async Task<IActionResult> MemoryStore(string text)
{
    var handler = new OpenAIHttpClientHandler();
    //创建embedding实例
    var memoryWithCustomDb = new MemoryBuilder()
        .WithOpenAITextEmbeddingGeneration(
        "text-embedding-ada-002",
        OpenAIOptions.Key,
        httpClient: new HttpClient(handler)
    )
        .WithMemoryStore(new VolatileMemoryStore())
        .Build();

    //支持的vector-db
    //https://learn.microsoft.com/en-us/semantic-kernel/memories/vector-db

    var bilibiliFiles = BiliBiliData();
    var i = 0;
    foreach (var entry in bilibiliFiles)
    {
        await memoryWithCustomDb.SaveReferenceAsync(
            collection: "BiliBili",
            externalSourceName: "BiliBili",
            externalId: entry.Key,
            description: entry.Value,
            text: entry.Value
        );

        Console.Write($" #{++i} 保存成功.");
    }

    var memories = memoryWithCustomDb.SearchAsync(
        "BiliBili",
        text,
        limit: 2,
        minRelevanceScore: 0.5
    );

    string result = "";
    await foreach (MemoryQueryResult memory in memories)
    {
        result +=
            $"Id:{memory.Metadata.Id},Description:{memory.Metadata.Description},Relevance：{memory.Relevance}\n";
    }

    return Ok(result);
}

private Dictionary<string, string> BiliBiliData()
{
    return new Dictionary<string, string>
    {
        ["https://www.bilibili.com/video/BV1sr4y1f7zb/"] = "SK 插件Plugins及VSCode调试工具",
        ["https://www.bilibili.com/video/BV1Hw411Y71S"] = "SK 原生函数使用方法",
        ["https://www.bilibili.com/video/BV1zF411m7YA/"] = "SK 嵌套函数使用方法",
        ["https://www.bilibili.com/video/BV1F841117Jc/"] =
            "SK 原生函数及嵌套函数串联使用方法",
        ["https://www.bilibili.com/video/BV12j41187GX/"] = "SK Plan流程编排",
        ["https://www.bilibili.com/video/BV1nm4y1V7dz/"] = "SK 意图识别、json提取",
        ["https://www.bilibili.com/video/BV1Qj41147i6/"] = "SK 依赖注入、Pipeline",
    };
}
```

- 使用ISemanticTextMemory（textMemory）对象存储和检索内存。

```cs
/// <summary>
/// 第1部分：使用ISemanticTextMemory（textMemory）对象存储和检索内存。
///这是一种从代码角度存储内存的简单方法，无需使用内核。
/// </summary>
/// <returns></returns>
[HttpPost]
public async Task<IActionResult> TextMemory1()
{
    IMemoryStore memoryStore = new VolatileMemoryStore();
    var handler = new OpenAIHttpClientHandler();
    var embeddingGenerator = new OpenAITextEmbeddingGenerationService(
        "text-embedding-ada-002",
        OpenAIOptions.Key,
        httpClient: new HttpClient(handler)
    );

    SemanticTextMemory textMemory = new(memoryStore, embeddingGenerator);

    await textMemory.SaveInformationAsync(
        "Xzy",
        id: "info1",
        text: "我的名字是许泽宇",
        cancellationToken: default
    );
    await textMemory.SaveInformationAsync(
        "Xzy",
        id: "info2",
        text: "我的职位是架构师",
        cancellationToken: default
    );
    await textMemory.SaveInformationAsync(
        "Xzy",
        id: "info3",
        text: "我有13年工作经验",
        cancellationToken: default
    );
    await textMemory.SaveInformationAsync(
        "Xzy",
        id: "info4",
        text: "我擅长.Net Core、微服务、云原生、AI",
        cancellationToken: default
    );

    var memoryPlugin = new TextMemoryPlugin(textMemory);
    var memoryFunctions = _kernel.ImportPluginFromObject(memoryPlugin);
    MemoryQueryResult? lookup = await textMemory.GetAsync(
        "Xzy",
        "info1",
        cancellationToken: default
    );
    Console.WriteLine(" 'info1':" + lookup?.Metadata.Text ?? "ERROR: memory 没找到");

    return Ok();
}
```

- 创建TextMemoryPlugin，通过内核存储和检索内存。

```cs
/// <summary>
///第2部分：创建TextMemoryPlugin，通过内核存储和检索内存。
///这使得语义功能和人工智能（通过规划者）能够访问记忆
/// </summary>
/// <returns></returns>
[HttpPost]
public async Task<IActionResult> TextMemory2()
{
  IMemoryStore memoryStore = new VolatileMemoryStore();
  //AzureOpenAITextEmbeddingGenerationService
  var handler = new OpenAIHttpClientHandler();
  var embeddingGenerator = new OpenAITextEmbeddingGenerationService(
      "text-embedding-ada-002",
      OpenAIOptions.Key,
      httpClient: new HttpClient(handler)
  );

  SemanticTextMemory textMemory = new(memoryStore, embeddingGenerator);
  var memoryPlugin = new TextMemoryPlugin(textMemory);
  var memoryFunctions = _kernel.ImportPluginFromObject(memoryPlugin);
  await _kernel.InvokeAsync(
      memoryFunctions["Save"],
      new()
      {
          [TextMemoryPlugin.CollectionParam] = "Xzy",
          [TextMemoryPlugin.KeyParam] = "info1",
          ["input"] = "我的名字是许泽宇",
      },
      cancellationToken: default
  );
  var result = await _kernel.InvokeAsync(
      memoryFunctions["Retrieve"],
      new()
      {
          [TextMemoryPlugin.CollectionParam] = "Xzy",
          [TextMemoryPlugin.KeyParam] = "info1",
      },
      cancellationToken: default
  );
  return Ok(result.GetValue<string>());
}
```

- 用语义搜索回忆相似的想法




```cs
/// <summary>
///第三部分：用语义搜索回忆相似的想法
///使用AI嵌入基于意图而非特定密钥对内存进行模糊查找。
/// </summary>
/// <returns></returns>
[HttpPost]
public async Task<IActionResult> TextMemory3()
{
    IMemoryStore memoryStore = new VolatileMemoryStore();
    var handler = new OpenAIHttpClientHandler();
    var embeddingGenerator = new OpenAITextEmbeddingGenerationService(
        "text-embedding-ada-002",
        OpenAIOptions.Key,
        httpClient: new HttpClient(handler)
    );

    SemanticTextMemory textMemory = new(memoryStore, embeddingGenerator);
    await textMemory.SaveInformationAsync(
        "Xzy",
        id: "info1",
        text: "我的名字是许泽宇",
        cancellationToken: default
    );
    await textMemory.SaveInformationAsync(
        "Xzy",
        id: "info2",
        text: "我的职位是架构师",
        cancellationToken: default
    );
    await textMemory.SaveInformationAsync(
        "Xzy",
        id: "info3",
        text: "我有13年工作经验",
        cancellationToken: default
    );
    await textMemory.SaveInformationAsync(
        "Xzy",
        id: "info4",
        text: "我擅长.Net Core、微服务、云原生、AI",
        cancellationToken: default
    );

    await foreach (
        var answer in textMemory.SearchAsync(
            collection: "Xzy",
            query: "我叫什么名字?",
            limit: 2,
            minRelevanceScore: 0.79,
            withEmbeddings: true,
            cancellationToken: default
        )
    )
    {
        Console.WriteLine($"Answer: {answer.Metadata.Text} ");
    }
    return Ok();
}
```

- TextMemoryPugin在语义函数中的回忆

```cs
/// <summary>
///TextMemoryPugin在语义函数中的回忆
///渲染提示模板时查找相关内存，然后将渲染的提示发送到
///用于回答自然语言查询的文本完成模型。
/// </summary>
/// <returns></returns>
[HttpPost]
public async Task<IActionResult> TextMemory4()
{
    IMemoryStore memoryStore = new VolatileMemoryStore();
    var handler = new OpenAIHttpClientHandler();
    var embeddingGenerator = new OpenAITextEmbeddingGenerationService(
        "text-embedding-ada-002",
        OpenAIOptions.Key,
        httpClient: new HttpClient(handler)
    );

    SemanticTextMemory textMemory = new(memoryStore, embeddingGenerator);

    await textMemory.SaveInformationAsync(
        "Xzy",
        id: "info1",
        text: "我的名字是许泽宇",
        cancellationToken: default
    );
    await textMemory.SaveInformationAsync(
        "Xzy",
        id: "info2",
        text: "我的职位是架构师",
        cancellationToken: default
    );
    await textMemory.SaveInformationAsync(
        "Xzy",
        id: "info3",
        text: "我有13年工作经验",
        cancellationToken: default
    );
    await textMemory.SaveInformationAsync(
        "Xzy",
        id: "info4",
        text: "我擅长.Net Core、微服务、云原生、AI",
        cancellationToken: default
    );
    await textMemory.SaveInformationAsync(
        "Xzy",
        id: "info5",
        text: "我住在武汉",
        cancellationToken: default
    );
    var memoryPlugin = new TextMemoryPlugin(textMemory);
    var memoryFunctions = _kernel.ImportPluginFromObject(memoryPlugin);
    var aboutMeOracle = _kernel.CreateFunctionFromPrompt(
        RecallFunctionDefinition,
        new OpenAIPromptExecutionSettings() { MaxTokens = 100 }
    );

    var result = await _kernel.InvokeAsync(
        aboutMeOracle,
        new KernelArguments()
        {
            [TextMemoryPlugin.CollectionParam] = "Xzy",
            [TextMemoryPlugin.RelevanceParam] = "0.79",
            [TextMemoryPlugin.LimitParam] = "2",
            [TextMemoryPlugin.InputParam] = "我住在哪里?",
        },
        cancellationToken: default
    );
    return Ok(result.GetValue<string>());
}

private const string RecallFunctionDefinition =
    @"
回答问题时只考虑以下事实：
开始事实
关于我： {{Recall '我在哪里长大的？'}}
关于我： {{Recall '我现在住在哪里？'}}
结束事实

问题: {{$input}}

答案:
";
```



## official

### 1.基本Kernel使用和概念

> - 开始学习语义内核，并了解关键概念。

#### 1.1 基本提示对话

- **简单提示调用**：可以通过`InvokePromptAsync`方法直接向内核发送文本提示，并获取其响应。例如，询问“天空是什么颜色的？”。
- **模板化提示**：允许你定义参数化的提示模板，并在调用时传入具体参数值。比如，通过设置`"topic"`为“海洋”，然后调用`InvokePromptAsync`来询问“海洋是什么颜色的？”。
- **流式输出**：对于需要长时间处理或逐步返回结果的任务，可以使用`InvokePromptStreamingAsync`方法来接收部分完成的结果更新。
- **执行设置自定义**：可以在调用提示时指定额外的执行参数，如最大返回字符数(`MaxTokens`)、生成文本的随机性程度(`Temperature`)等，以控制AI生成内容的行为。
- **格式化响应**：还可以通过配置执行设置中的`ResponseFormat`属性，要求内核以特定格式（如JSON对象）返回结果，这在需要结构化数据输出时非常有用。

```cs
/// <summary>
/// 展示如何创建 <see cref="Kernel"/> 并使用它来执行提示。
/// </summary>
public async Task CreateKernelAsync()
{
    // 使用 OpenAI 聊天补全创建一个内核
    var kernel = ConfigExtensions.GetKernel("DouBao");

    // 示例 1. 使用提示调用内核并显示结果
    Console.WriteLine(await kernel.InvokePromptAsync("天空是什么颜色的？"));
    Console.WriteLine();

    // 示例 2. 使用模板化提示调用内核并显示结果
    KernelArguments arguments = new() { { "topic", "海洋" } };
    Console.WriteLine(await kernel.InvokePromptAsync("{{$topic}} 是什么颜色的？", arguments));
    Console.WriteLine();

    // 示例 3. 使用模板化提示调用内核并将结果流式传输到显示
    await foreach (
        var update in kernel.InvokePromptStreamingAsync("{{$topic}} 是什么颜色的？请提供详细解释。", arguments)
    )
    {
        Console.Write(update);
    }

    Console.WriteLine(string.Empty);

    // 示例 4. 使用模板化提示和执行设置调用内核
    arguments = new(new OpenAIPromptExecutionSettings { MaxTokens = 500, Temperature = 0.5 })
    {
        { "topic", "狗" },
    };
    Console.WriteLine(await kernel.InvokePromptAsync("给我讲一个关于 {{$topic}} 的故事", arguments));

    // 示例 5. 使用模板化提示和配置为返回 JSON 的执行设置调用内核
    arguments = new(new OpenAIPromptExecutionSettings { ResponseFormat = "json_object" })
    {
        { "topic", "巧克力" },
    };
    Console.WriteLine(
        await kernel.InvokePromptAsync("以 JSON 格式创建一个 {{$topic}} 蛋糕的食谱", arguments)
    );
}
```



#### 1.2 使用KernelPlugin

- 插件支持枚举，见案例4

```cs

/// <summary>
/// 展示了加载<see cref="KernelPlugin"/>实例的不同方法。
/// </summary>
public async Task AddPluginsAsync()
{
    // Create a kernel with OpenAI chat completion
    IKernelBuilder kernelBuilder = Kernel.CreateBuilder();
    kernelBuilder.AddOpenAIChat(
        ConfigExtensions
        .LoadConfigFromJson("./tmpsecrets.json")
        .GetSection("DouBao")
        .Get<OpenAIConfig>()
    );

    kernelBuilder.Plugins.AddFromType<TimeInformation>();
    kernelBuilder.Plugins.AddFromType<WidgetFactory>();
    Kernel kernel = kernelBuilder.Build();

    // 示例1。使用提示调用内核，询问AI无法提供的信息，并可能产生幻觉
    Console.WriteLine(await kernel.InvokePromptAsync("现在距离圣诞节已经过去了多少天？"));

    // 示例2。使用模板化提示调用内核，该提示调用插件并显示结果
    Console.WriteLine(
        await kernel.InvokePromptAsync(
            "当前时间是 {{TimeInformation.GetCurrentUtcTime}} 。现在距离圣诞节已经过去了多少天？"
        )
    );

    // 示例3。使用提示调用内核，并允许AI自动调用函数
    OpenAIPromptExecutionSettings settings =
        new() { FunctionChoiceBehavior = FunctionChoiceBehavior.Auto(), };
    Console.WriteLine(
        await kernel.InvokePromptAsync("今天距离圣诞节已经过去了多少天？ 解释你的想法。", new(settings))
    );

    // 示例4。使用提示调用内核，并允许AI自动调用使用枚举的函数
    // Useful 随机颜色
    Console.WriteLine(
        await kernel.InvokePromptAsync(
            "Create a handy lime colored widget for me.",
            new(settings)
        )
    );
    // Decorative 随机颜色
    Console.WriteLine(
        await kernel.InvokePromptAsync(
            "Create a beautiful scarlet colored widget for me.",
            new(settings)
        )
    );
    // Decorative 两种颜色
    Console.WriteLine(
        await kernel.InvokePromptAsync(
            "Create an attractive maroon and navy colored widget for me.",
            new(settings)
        )
    );
}

/// <summary>
/// 一个返回当前时间的插件。
/// </summary>
private class TimeInformation
{
    [KernelFunction]
    [Description("获取今天现在的UTC时间")]
    public string GetCurrentUtcTime() => DateTime.UtcNow.ToString("yyyy-MM-dd HH:mm:ss");
}

/// <summary>
/// 一个创建小部件的插件。
/// </summary>
private class WidgetFactory
{
    [KernelFunction]
    [Description("Creates a new widget of the specified type and colors")]
    public WidgetDetails CreateWidget(
        [Description("The type of widget to be created")] WidgetType widgetType,
        [Description("The colors of the widget to be created")] WidgetColor[] widgetColors
    )
    {
        var colors = string.Join('-', widgetColors.Select(c => c.GetDisplayName()).ToArray());
        return new()
        {
            SerialNumber = $"{widgetType}-{colors}-{Guid.NewGuid()}",
            Type = widgetType,
            Colors = widgetColors,
        };
    }
}

/// <summary>
/// <see cref="JsonConverter"/> 用于转换枚举类型
/// </summary>
[JsonConverter(typeof(JsonStringEnumConverter))]
public enum WidgetType
{
    [Description("A widget that is useful.")]
    Useful,

    [Description("A widget that is decorative.")]
    Decorative,
}

/// <summary>
/// <see cref="JsonConverter"/> 用于转换枚举类型
/// </summary>
[JsonConverter(typeof(JsonStringEnumConverter))]
public enum WidgetColor
{
    [Description("Use when creating a red item.")]
    Red,

    [Description("Use when creating a green item.")]
    Green,

    [Description("Use when creating a blue item.")]
    Blue,
}

public class WidgetDetails
{
    public string SerialNumber { get; init; }
    public WidgetType Type { get; init; }
    public WidgetColor[] Colors { get; init; }
}
```



#### 1.3 使用过滤器

**提示词过滤器**

- 过滤密码等敏感数据

```cs
/// <summary>
/// 展示如何使用提示过滤器来确保提示以负责任的方式呈现。
/// </summary>
public async Task AddPromptFilterAsync()
{
    // 使用 OpenAI 的聊天完成功能创建内核
    var configRoot = ConfigExtensions.LoadConfigFromJson();
    var chatConfig = configRoot.GetSection("DouBao").Get<OpenAIConfig>();
    var builder = Kernel
        .CreateBuilder()
        .AddOpenAIChatCompletion(
        modelId: chatConfig.ModelId,
        apiKey: chatConfig.ApiKey,
        endpoint: chatConfig.Endpoint
    );

    // 向内核添加提示过滤器
    builder.Services.AddSingleton<IPromptRenderFilter, PromptFilter>();

    var kernel = builder.Build();

    KernelArguments arguments = new() { { "card_number", "4444 3333 2222 1111" } };

    var result = await kernel.InvokePromptAsync(
        "请告诉我关于这个信用卡号 {{$card_number}} 的一些有用信息？",
        arguments
    );

    Console.WriteLine(result);

    // 输出：对不起，但我无法提供帮助。
}
}

internal sealed class PromptFilter : IPromptRenderFilter
{
    /// <summary>
    /// 在提示渲染之前异步调用的方法。
    /// </summary>
    /// <param name="context">包含提示渲染细节的 <see cref="PromptRenderContext"/> 实例。</param>
    /// <param name="next">指向管道中下一个过滤器或提示渲染操作本身的委托。如果不调用它，则不会调用下一个过滤器或提示渲染。</param>
    public async Task OnPromptRenderAsync(
        PromptRenderContext context,
        Func<PromptRenderContext, Task> next
    )
    {
        if (context.Arguments.ContainsName("card_number"))
        {
            context.Arguments["card_number"] = "**** **** **** ****";
        }
        await next(context);
        context.RenderedPrompt += " NO SEXISM, RACISM OR OTHER BIAS/BIGOTRY";
        System.Console.WriteLine(context.RenderedPrompt);
    }
}
```



**函数过滤器**

- 类似于方法aop，在调用function的前后执行处理

```cs
public async Task ObservabilityWithFiltersAsync()
{
    // 使用 OpenAI 的聊天完成功能创建内核
    var configRoot = ConfigExtensions.LoadConfigFromJson();
    var chatConfig = configRoot.GetSection("DouBao").Get<OpenAIConfig>();
    var builder = Kernel
        .CreateBuilder()
        .AddOpenAIChatCompletion(
        modelId: chatConfig.ModelId,
        apiKey: chatConfig.ApiKey,
        endpoint: chatConfig.Endpoint
    );
    builder.Plugins.AddFromType<TimeInformation>();
    // 使用依赖注入添加过滤器
    builder.Services.AddSingleton<IFunctionInvocationFilter, MyFunctionFilter>();

    Kernel kernel = builder.Build();

    // 不使用依赖注入添加过滤器
    kernel.PromptRenderFilters.Add(new MyPromptFilter());

    // 使用提示调用内核，并允许AI自动调用函数
    OpenAIPromptExecutionSettings settings = new()
    {
        FunctionChoiceBehavior = FunctionChoiceBehavior.Auto(),
    };
    Console.WriteLine(
        await kernel.InvokePromptAsync(
            "距离圣诞节还有多少天？请简单解释你的思考过程。",
            new(settings)
        )
    );
}

/// <summary>
/// 返回当前时间的插件。
/// </summary>
private sealed class TimeInformation
{
    [KernelFunction]
    [Description("获取当前UTC时间。")]
    public string GetCurrentUtcTime() => DateTime.UtcNow.ToString("yyyy-MM-dd HH:mm:ss");
}

/// <summary>
/// 用于可观测性的函数调用过滤器。
/// </summary>
private sealed class MyFunctionFilter : IFunctionInvocationFilter
{
    public async Task OnFunctionInvocationAsync(
        FunctionInvocationContext context,
        Func<FunctionInvocationContext, Task> next
    )
    {
        System.Console.WriteLine($"Invoking {context.Function.Name}");
        await next(context);

        var metadata = context.Result.Metadata;
        if (metadata is not null && metadata.ContainsKey("Usage"))
        {
            System.Console.WriteLine($"Token usage: {metadata["Usage"]?.AsJson()}");
        }
    }
}

/// <summary>
/// 用于可观测性的提示过滤器。
/// </summary>
private sealed class MyPromptFilter : IPromptRenderFilter
{
    public async Task OnPromptRenderAsync(
        PromptRenderContext context,
        Func<PromptRenderContext, Task> next
    )
    {
        System.Console.WriteLine($"Rendering prompt for {context.Function.Name}");
        await next(context);
        System.Console.WriteLine($"Rendered prompt: {context.RenderedPrompt}");
    }
}
```



#### 1.4 管道

- 构建一个管道函数，整合一系列的function依次执行

```cs
/// <summary>
/// 提供了一个示例，演示如何将多个函数组合成一个单一的函数，
/// 该函数按顺序调用它们，将一个函数的输出作为下一个函数的输入传递。
/// </summary>
public async Task CreateFunctionPipelineAsync()
{
    var configRoot = ConfigExtensions.LoadConfigFromJson();
    var chatConfig = configRoot.GetSection("DouBao").Get<OpenAIConfig>();
    var builder = Kernel
        .CreateBuilder()
        .AddOpenAIChatCompletion(
        modelId: chatConfig.ModelId,
        apiKey: chatConfig.ApiKey,
        endpoint: chatConfig.Endpoint
    );
    builder.Services.AddLogging(c => c.AddConsole().SetMinimumLevel(LogLevel.Trace));
    Kernel kernel = builder.Build();

    Console.WriteLine("================ PIPELINE ================");
    {
        // 创建一个函数管道，它会解析字符串为双精度浮点数，乘以另一个双精度浮点数，截断结果到整数，然后将其转换为人类可读的格式。
        KernelFunction parseDouble = KernelFunctionFactory.CreateFromMethod(
            (string s) => double.Parse(s, CultureInfo.InvariantCulture),
            "parseDouble"
        );
        KernelFunction multiplyByN = KernelFunctionFactory.CreateFromMethod(
            (double i, double n) => i * n,
            "multiplyByN"
        );
        KernelFunction truncate = KernelFunctionFactory.CreateFromMethod(
            (double d) => (int)d,
            "truncate"
        );
        KernelFunction humanize = KernelFunctionFactory.CreateFromPrompt(
            new PromptTemplateConfig()
            {
                Template = "Spell out this number in English: {{$number}}",
                InputVariables = [new() { Name = "number" }],
            }
        );
        KernelFunction pipeline = KernelFunctionCombinators.Pipe(
            [parseDouble, multiplyByN, truncate, humanize],
            "pipeline"
        );

        KernelArguments args = new() { ["s"] = "123.456", ["n"] = (double)78.90 };

        // - parseDouble 函数将被调用，从参数中读取 "123.456" 并解析为 (double)123.456。
        // - multiplyByN 函数将被调用，使用 i=123.456 和 n=78.90，并返回 (double)9740.6784。
        // - truncate 函数将被调用，使用 d=9740.6784，并返回 (int)9740，这将是最终结果。
        Console.WriteLine(await pipeline.InvokeAsync(kernel, args));
    }

    Console.WriteLine("================ GRAPH ================");
    {
        KernelFunction rand = KernelFunctionFactory.CreateFromMethod(
            () => Random.Shared.Next(),
            "GetRandomInt32"
        );
        KernelFunction mult = KernelFunctionFactory.CreateFromMethod(
            (int i, int j) => i * j,
            "Multiply"
        );
        KernelFunction graph = KernelFunctionCombinators.Pipe(
            [(rand, "i"), (rand, "j"), (mult, "")],
            "graph"
        );
        Console.WriteLine(await graph.InvokeAsync(kernel));
    }
}
```



**KernelFunctionCombinators**

- 现在只能自己写这里的逻辑，SK中已删除。

```cs
/// <summary>
/// 函数管道编排器
/// </summary>
public static class KernelFunctionCombinators
{
    /// <summary>
    /// 调用一个函数管道，按顺序运行每个函数，并将一个函数的输出作为下一个函数的第一个参数传递。
    /// </summary>
    /// <param name="functions">要调用的函数管道。</param>
    /// <param name="kernel">用于操作的内核。</param>
    /// <param name="arguments">参数。</param>
    /// <param name="cancellationToken">用于监视取消请求的取消令牌。</param>
    /// <returns>KernelFunction 运行结果</returns>
    public static Task<FunctionResult> InvokePipelineAsync(
        IEnumerable<KernelFunction> functions,
        Kernel kernel,
        KernelArguments arguments,
        CancellationToken cancellationToken
    ) => Pipe(functions).InvokeAsync(kernel, arguments, cancellationToken);

    /// <summary>
    /// 调用一个函数管道，按顺序运行每个函数，并将一个函数的输出作为命名参数传递给下一个函数。
    /// </summary>
    /// <param name="functions">要调用的函数序列，以及分配给函数调用结果的参数名称。</param>
    /// <param name="kernel">用于操作的内核。</param>
    /// <param name="arguments">参数。</param>
    /// <param name="cancellationToken">用于监视取消请求的取消令牌。</param>
    /// <returns>KernelFunction 运行结果</returns>
    public static Task<FunctionResult> InvokePipelineAsync(
        IEnumerable<(KernelFunction Function, string OutputVariable)> functions,
        Kernel kernel,
        KernelArguments arguments,
        CancellationToken cancellationToken
    ) => Pipe(functions).InvokeAsync(kernel, arguments, cancellationToken);

    /// <summary>
    /// 创建一个函数，其调用将依次调用每个提供的函数。
    /// </summary>
    /// <param name="functions">要调用的函数管道。</param>
    /// <param name="functionName">组合操作的名称。</param>
    /// <param name="description">组合操作的描述。</param>
    /// <returns>最后一个函数的结果。</returns>
    /// <remarks>
    /// 一个函数的结果将作为下一个函数的第一个参数传递。
    /// </remarks>
    public static KernelFunction Pipe(
        IEnumerable<KernelFunction> functions,
        string? functionName = null,
        string? description = null
    )
    {
        ArgumentNullException.ThrowIfNull(functions);
        KernelFunction[] funcs = functions.ToArray();
        Array.ForEach(funcs, f => ArgumentNullException.ThrowIfNull(f));

        // 创建一个包含函数和输出变量名的元组数组。如果不是最后一个函数，获取下一个函数的第一个参数名
        var funcsAndVars = new (KernelFunction Function, string OutputVariable)[funcs.Length];
        for (int i = 0; i < funcs.Length; i++)
        {
            string p = "";
            if (i < funcs.Length - 1)
            {
                var parameters = funcs[i + 1].Metadata.Parameters;
                if (parameters.Count > 0)
                {
                    p = parameters[0].Name;
                }
            }
            // 将当前函数和下一个函数的第一个参数名存入元组数组
            funcsAndVars[i] = (funcs[i], p);
        }
        return Pipe(funcsAndVars, functionName, description);
    }

    /// <summary>
    /// 创建一个函数，其调用将依次调用每个提供的函数。
    /// </summary>
    /// <param name="functions">要调用的函数管道，以及分配给函数调用结果的参数名称。</param>
    /// <param name="functionName">组合操作的名称。</param>
    /// <param name="description">组合操作的描述。</param>
    /// <returns>最后一个函数的结果。</returns>
    /// <remarks>
    /// 一个函数的结果将作为下一个函数的第一个参数传递。
    /// </remarks>
    public static KernelFunction Pipe(
        IEnumerable<(KernelFunction Function, string OutputVariable)> functions,
        string? functionName = null,
        string? description = null
    )
    {
        ArgumentNullException.ThrowIfNull(functions);

        (KernelFunction Function, string OutputVariable)[] arr = functions.ToArray();
        Array.ForEach(
            arr,
            f =>
            {
                ArgumentNullException.ThrowIfNull(f.Function);
                ArgumentNullException.ThrowIfNull(f.OutputVariable);
            }
        );
        // 使用 KernelFunctionFactory 创建一个新的 KernelFunction
        return KernelFunctionFactory.CreateFromMethod(
            async (Kernel kernel, KernelArguments arguments) =>
            {
                FunctionResult? result = null;
                // 遍历函数数组，依次调用每个函数。如果不是最后一个函数，将当前函数的结果存入参数集合中，作为下一个函数的输入
                for (int i = 0; i < arr.Length; i++)
                {
                    result = await arr[i]
                        .Function.InvokeAsync(kernel, arguments)
                        .ConfigureAwait(false);
                    if (i < arr.Length - 1)
                    {
                        arguments[arr[i].OutputVariable] = result.GetValue<object>();
                    }
                }

                return result;
            },
            functionName,
            description
        );
    }
}
```



#### 1.5 OpenAPI导入

- 首先安装Microsoft.SemanticKernel.Plugins.OpenApi
- 然后加载openapi格式的接口json文件，此后sk将创建出对应接口的function。

```cs
/// <summary>
/// 基本使用
/// </summary>
public async Task AddOpenAPIPluginsAsync()
{
    var kernel = ConfigExtensions.GetKernel("DouBao");

    // 加载 OpenAPI 插件
    var plugin = await kernel.ImportPluginFromOpenApiAsync(
        "RepairService",
        "./Resources/repair-service.json"
    );
    PromptExecutionSettings settings = new()
    {
        FunctionChoiceBehavior = FunctionChoiceBehavior.Auto(),
    };
    Console.WriteLine(
        await kernel.InvokePromptAsync("List all of the repairs .", new(settings))
    );
}

/// <summary>
/// 展示了如何转换一个 Open API <see cref="KernelPlugin"/> 实例以支持依赖注入。
/// </summary>
public async Task TransformOpenAPIPluginsAsync()
{
    // 创建一个带有 OpenAI 聊天完成功能的内核
    var serviceProvider = BuildServiceProvider();
    var kernel = serviceProvider.GetRequiredService<Kernel>();

    // 加载 OpenAPI 插件
    var plugin = await kernel.CreatePluginFromOpenApiAsync(
        "RepairService",
        "./Resources/repair-service.json"
    );

    // 转换插件以使用 IMechanicService 通过依赖注入
    kernel.Plugins.Add(TransformPlugin(plugin));

    PromptExecutionSettings settings = new()
    {
        FunctionChoiceBehavior = FunctionChoiceBehavior.Auto(),
    };

    // 预约一次更换旧发动机油并替换为新机油的服务.
    Console.WriteLine(
        await kernel.InvokePromptAsync(
            "Book an appointment to drain the old engine oil and replace it with fresh oil.",
            new(settings)
        )
    );
}

/// <summary>
/// 构建一个可以用来解析服务的 ServiceProvider。
/// </summary>
private ServiceProvider BuildServiceProvider()
{
    ServiceCollection collection = [];
    collection.AddSingleton<IMechanicService>(new FakeMechanicService());
    var chatConfig = ConfigExtensions.GetConfig<OpenAIConfig>("./tmpsecrets.json", "DouBao");
    collection
        .AddKernel()
        .AddOpenAIChatCompletion(
        modelId: chatConfig.ModelId,
        apiKey: chatConfig.ApiKey,
        endpoint: chatConfig.Endpoint
    );
    return collection.BuildServiceProvider();
}

/// <summary>
/// 修改 KernelPlugin 实例中特定函数的行为，而不改变其他函数。此处改变 createRepair 函数的行为。
/// </summary>
public static KernelPlugin TransformPlugin(KernelPlugin plugin)
{
    List<KernelFunction>? functions = [];
    foreach (var function in plugin)
    {
        if (function.Name == "createRepair")
        {
            functions.Add(CreateRepairFunction(function));
        }
        else
        {
            functions.Add(function);
        }
    }
    return KernelPluginFactory.CreateFromFunctions(plugin.Name, plugin.Description, functions);
}

/// <summary>
/// 创建一个用于 createRepair 操作的 <see cref="KernelFunction"/> 实例，该实例只接收
/// title 和 description 参数，并且有一个委托使用 IMechanicService 来获取 assignedTo。
/// 相当于和原先引入openapi中的createRepair减少了几个参数
/// </summary>
public static KernelFunction CreateRepairFunction(KernelFunction function) =>
    KernelFunctionFactory.CreateFromMethod(
    (
        Kernel kernel,
        KernelFunction currentFunction,
        KernelArguments arguments,
        [FromKernelServices] IMechanicService mechanicService,
        CancellationToken cancellationToken
    ) =>
    {
        arguments.Add("assignedTo", mechanicService.GetMechanic());
        arguments.Add("date", DateTime.UtcNow.ToString("R"));

        return function.InvokeAsync(kernel, arguments, cancellationToken);
    },
    new KernelFunctionFromMethodOptions()
    {
        FunctionName = function.Name,
        Description = function.Description,
        Parameters = function
            .Metadata.Parameters.Where(e => e.Name == "title" || e.Name == "description")
            .ToList(),
        ReturnParameter = function.Metadata.ReturnParameter,
    }
);

/// <summary>
/// 获取分配给下一个工作的技工的服务接口。
/// </summary>
public interface IMechanicService
{
    /// <summary>
    /// 返回分配给下一个工作的技工的名字。
    /// </summary>
    string GetMechanic();
}

/// <summary>
/// <see cref="IMechanicService"/> 的模拟实现。
/// </summary>
public class FakeMechanicService : IMechanicService
{
    public string GetMechanic() => "Bob";
}
```



### 2.智能体













































































































